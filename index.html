<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>AI Emotion-Friendly Tutor</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Calm Pastel Theme -->
<style>
    body {
        font-family: "Arial", sans-serif;
        background: #e7f5ff; /* pastel light blue */
        color: #003f5c;
        margin: 0;
        padding: 20px;
        text-align: center;
    }
    h1 {
        color: #005f73;
        margin-bottom: 5px;
    }
    p {
        max-width: 600px;
        margin: 0 auto 20px auto;
        color: #02577a;
    }
    button {
        background: #8bd3dd; /* pastel teal */
        border: none;
        padding: 12px 22px;
        font-size: 16px;
        border-radius: 12px;
        cursor: pointer;
        color: white;
        box-shadow: 0 4px 10px rgba(0,0,0,0.15);
        transition: 0.2s;
    }
    button:hover {
        background: #6cc5cf;
    }

    #webcam-container canvas {
        border-radius: 20px;       /* rounded */
        box-shadow: 0 6px 14px rgba(0,0,0,0.18); /* soft shadow */
        margin-top: 20px;
    }

    #label-container div {
        background: white;
        margin: 8px auto;
        padding: 10px;
        max-width: 300px;
        border-radius: 10px;
        box-shadow: 0 3px 8px rgba(0,0,0,0.1);
        font-weight: bold;
        color: #005f73;
    }
</style>
</head>

<body>

<h1>AI Emotion-Friendly Tutor</h1>
<p>
This tool uses a Teachable Machine model to detect three states: <b>Engaged</b>, 
<b>Confused</b>, and <b>Focused</b>. Itâ€™s designed to help understand how students 
interact with digital learning in real time.
</p>

<button onclick="startModel()">Start Model</button>

<div id="webcam-container"></div>
<div id="label-container"></div>

<!-- Scripts -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>

<script>
const URL = "./my_model/";
let model, webcam, maxPredictions, labelContainer;

async function startModel() {
    const modelURL = URL + "model.json";
    const metadataURL = URL + "metadata.json";

    // Load model
    model = await tmImage.load(modelURL, metadataURL);
    maxPredictions = model.getTotalClasses();

    // Setup webcam
    const flip = true;
    webcam = new tmImage.Webcam(250, 250, flip);
    await webcam.setup();
    await webcam.play();
    window.requestAnimationFrame(loop);

    // Attach webcam
    document.getElementById("webcam-container").appendChild(webcam.canvas);

    // Prepare label boxes
    labelContainer = document.getElementById("label-container");
    labelContainer.innerHTML = "";
    for (let i = 0; i < maxPredictions; i++) {
        labelContainer.appendChild(document.createElement("div"));
    }
}

async function loop() {
    webcam.update();
    await predict();
    window.requestAnimationFrame(loop);
}

async function predict() {
    const prediction = await model.predict(webcam.canvas);
    for (let i = 0; i < maxPredictions; i++) {
        labelContainer.childNodes[i].innerHTML =
            prediction[i].className + ": " + prediction[i].probability.toFixed(2);
    }
}
</script>

</body>
</html>
